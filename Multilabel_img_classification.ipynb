{"cells":[{"cell_type":"markdown","metadata":{"id":"TcMQFdvwJgBq"},"source":["# Assignment 2 : Multi-label Image Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2SreyOONJgBv"},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","from sklearn.metrics import average_precision_score\n","from PIL import Image, ImageDraw\n","import matplotlib.pyplot as plt\n","from kaggle_submission import output_submission_csv\n","from classifier import Classifier\n","from voc_dataloader import VocDataset, VOC_CLASSES\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"jLJTx0zTJgBx"},"source":["In this assignment, you train a classifier to do multi-label classificaton on the PASCAL VOC 2007 dataset. The dataset has 20 different class which can appear in any given image. Your classifier will predict whether each class appears in an image. This task is slightly different from exclusive multiclass classification like the ImageNet competition where only a single most appropriate class is predicted for an image."]},{"cell_type":"markdown","metadata":{"id":"DaHf_3T8JgBy"},"source":["## Reading Pascal Data"]},{"cell_type":"markdown","metadata":{"id":"x4NP9bdSJgBy"},"source":["### Loading Training Data"]},{"cell_type":"markdown","metadata":{"id":"rQBXy0s2JgBz"},"source":["In the following cell we will load the training data and also apply some transforms to the data. Feel free to apply more [transforms](https://pytorch.org/docs/stable/torchvision/transforms.html) for data augmentation which can lead to better performance. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_8yEgZTJgBz"},"outputs":[],"source":["# Transforms applied to the training data\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std= [0.229, 0.224, 0.225])\n","\n","train_transform = transforms.Compose([\n","            transforms.Resize(227),\n","            transforms.CenterCrop(227),\n","            transforms.ToTensor(),\n","            normalize\n","        ])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhCLcplAJgB0"},"outputs":[],"source":["ds_train = VocDataset('VOCdevkit_2007/VOC2007/','train',train_transform)"]},{"cell_type":"markdown","metadata":{"id":"pzdFkH6WJgB2"},"source":["### Loading Validation Data"]},{"cell_type":"markdown","metadata":{"id":"Wr8EAcDGJgB2"},"source":["We will load the test data for the PASCAL VOC 2007 dataset. Do __NOT__ add data augmentation transforms to validation data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyHD8oxUJgB3"},"outputs":[],"source":["# Transforms applied to the testing data\n","test_transform = transforms.Compose([\n","            transforms.Resize(227),\n","            transforms.CenterCrop(227),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qeCcqYjOJgB3"},"outputs":[],"source":["ds_val = VocDataset('VOCdevkit_2007/VOC2007/','val',test_transform)"]},{"cell_type":"markdown","metadata":{"id":"2FBJhVT3JgB4"},"source":["### Visualizing the Data\n","\n","PASCAL VOC has bounding box annotations in addition to class labels. Use the following code to visualize some random examples and corresponding annotations from the train set. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5s4MsQtJgB4"},"outputs":[],"source":["for i in range(5):\n","    idx = np.random.randint(0, len(ds_train.names)+1)\n","    _imgpath = os.path.join('VOCdevkit_2007/VOC2007/', 'JPEGImages', ds_train.names[idx]+'.jpg')\n","    img = Image.open(_imgpath).convert('RGB')\n","    draw = ImageDraw.Draw(img)\n","    for j in range(len(ds_train.box_indices[idx])):\n","        obj = ds_train.box_indices[idx][j]\n","        draw.rectangle(list(obj), outline=(255,0,0))\n","        draw.text(list(obj[0:2]), ds_train.classes[ds_train.label_order[idx][j]], fill=(0,255,0))\n","    plt.figure(figsize = (10,10))\n","    plt.imshow(np.array(img))"]},{"cell_type":"markdown","metadata":{"id":"_m9mjfGqJgB5"},"source":["# Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P74-gSq_JgB5"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evoP_-aOJgB5"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n","                                               batch_size=50, \n","                                               shuffle=True,\n","                                               num_workers=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYB9JVUZJgB5"},"outputs":[],"source":["val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n","                                               batch_size=50, \n","                                               shuffle=True,\n","                                               num_workers=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bFpX-ziWJgB6"},"outputs":[],"source":["def train_classifier(train_loader, classifier, criterion, optimizer):\n","    classifier.train()\n","    loss_ = 0.0\n","    losses = []\n","    for i, (images, labels) in enumerate(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        logits = classifier(images)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss)\n","    return torch.stack(losses).mean().item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0-QZRD5JgB6"},"outputs":[],"source":["def test_classifier(test_loader, classifier, criterion, print_ind_classes=True):\n","    classifier.eval()\n","    losses = []\n","    with torch.no_grad():\n","        y_true = np.zeros((0,21))\n","        y_score = np.zeros((0,21))\n","        for i, (images, labels) in enumerate(test_loader):\n","            images, labels = images.to(device), labels.to(device)\n","            logits = classifier(images)\n","            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n","            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n","            loss = criterion(logits, labels)\n","            losses.append(loss.item())\n","        aps = []\n","        # ignore first class which is background\n","        for i in range(1, y_true.shape[1]):\n","            ap = average_precision_score(y_true[:, i], y_score[:, i])\n","            if print_ind_classes:\n","                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(VOC_CLASSES[i], ap))\n","            aps.append(ap)\n","        \n","        mAP = np.mean(aps)\n","        test_loss = np.mean(losses)\n","        print('mAP: {0:.4f}'.format(mAP))\n","        print('Avg loss: {}'.format(test_loss))\n","        \n","    return mAP, test_loss, aps"]},{"cell_type":"markdown","metadata":{"id":"P_RojUjFJgB6"},"source":["## Modifying the network \n","\n","The network you are given as is will allow you to reach around 0.15-0.2 mAP. To meet the benchmark for this assignment you will need to improve the network. There are a variety of different approaches you should try:\n","\n","* Network architecture changes\n","    * Number of layers: try adding layers to make your network deeper\n","    * Batch normalization: adding batch norm between layers will likely give you a significant performance increase\n","    * Residual connections: as you increase the depth of your network, you will find that having residual connections like those in ResNet architectures will be helpful\n","* Optimizer: Instead of plain SGD, you may want to add a learning rate schedule, add momentum, or use one of the other optimizers you have learned about like Adam. Check the `torch.optim` package for other optimizers\n","* Data augmentation: You should use the `torchvision.transforms` module to try adding random resized crops and horizontal flips of the input data. Check `transforms.RandomResizedCrop` and `transforms.RandomHorizontalFlip` for this\n","* Epochs: Once you have found a generally good hyperparameter setting try training for more epochs\n","* Loss function: You might want to add weighting to the `MultiLabelSoftMarginLoss` for classes that are less well represented or experiment with a different loss function\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1b4v9EKJgB7"},"outputs":[],"source":["classifier = Classifier().to(device)\n","# You can can use this function to reload a network you have already saved previously\n","#classifier.load_state_dict(torch.load('voc_classifier.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MD_w2_pFJgB7"},"outputs":[],"source":["criterion = nn.MultiLabelSoftMarginLoss()\n","optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z42OyVl-JgB7"},"outputs":[],"source":["# Training the Classifier\n","NUM_EPOCHS = 25\n","TEST_FREQUENCY = 5\n","\n","for epoch in range(1, NUM_EPOCHS+1):\n","    print(\"Starting epoch number \" + str(epoch))\n","    train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n","    print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n","    if(epoch%TEST_FREQUENCY==0):\n","        mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n","        print('Evaluating classifier')\n","        print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Oy4uxfwJgB8"},"outputs":[],"source":["# Save the clssifier network\n","# Suggestion: you can save checkpoints of your network during training and reload them later\n","torch.save(classifier.state_dict(), './voc_classifier.pth')"]},{"cell_type":"markdown","metadata":{"id":"lcrZKJvSJgB8"},"source":["# Evaluate on test set\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zH992AzrJgB8"},"outputs":[],"source":["ds_test = VocDataset('VOCdevkit_2007/VOC2007test/','test', test_transform)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n","                                               batch_size=50, \n","                                               shuffle=False,\n","                                               num_workers=1)\n","\n","mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0oh3DMkJgB8"},"outputs":[],"source":["output_submission_csv('my_solution.csv', test_aps)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}